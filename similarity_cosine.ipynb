{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os, nltk, collections, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "cand_li = os.listdir(path+\"\\data\")\n",
    "direc0 = []\n",
    "for cand in cand_li:\n",
    "    direc0.append(os.listdir(path+\"\\data\\{}\\\\rawdata\".format(cand)))\n",
    "for a in range(len(direc0)):\n",
    "    for b in range(len(direc0[a])):\n",
    "        direc0[a][b] = path+\"\\data\\\\\" + cand_li[a] + \"\\\\rawdata\\\\\" + direc0[a][b]\n",
    "direc = []\n",
    "for a in range(len(direc0)):\n",
    "    for b in range(len(direc0[a])):\n",
    "        direc.append(direc0[a][b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(direc):\n",
    "    #print(\"cleaning candidate {}, document number {}\".format(cand_var, doc_num))\n",
    "    with open(direc, 'r', encoding='utf-8') as f:       \n",
    "        f = f.read()\n",
    "    f = f.lower()\n",
    "    f = f.replace('\\n', ' ')\n",
    "    f = f.replace('\\\"', '')\n",
    "    f = f.replace('\\'', '')\n",
    "    f = f.replace('/', '')\n",
    "    f = f.replace(',', '')\n",
    "    f = f.replace('.', '')\n",
    "    f = f.replace('?', '')\n",
    "    f = f.replace('!', '')\n",
    "    f = f.replace('`', '')\n",
    "    f = f.replace(';', '')\n",
    "    f = f.replace(':', '')\n",
    "    f = f.replace('(', '')\n",
    "    f = f.replace(')', '')\n",
    "    f = f.replace('_', '')\n",
    "    f = f.replace('—', '')\n",
    "    f = f.replace('$', '')\n",
    "    f = f.replace('-', '')\n",
    "    f = f.replace('@', '')\n",
    "    f = f.replace('%', '')\n",
    "    f = f.replace('&amp', '')\n",
    "    f = re.sub('\\d', '', f)\n",
    "    f = re.sub('\\s+', ' ', f)\n",
    "    f = re.sub('\\”', ' ', f)\n",
    "    f = re.sub(r'\\b\\w\\b', ' ', f) # 剔除一個字的\n",
    "    \n",
    "    #斷詞\n",
    "    f = f.split()\n",
    "    \n",
    "    #製作stopwordlist\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    #remove stopwords\n",
    "    f1 = []\n",
    "    for n in range(len(f)):\n",
    "        if f[n] not in stopwords_list:\n",
    "            f1.append(f[n])\n",
    "    \n",
    "    #stemming\n",
    "    #from nltk.stem.porter import PorterStemmer\n",
    "    #pt = PorterStemmer()\n",
    "    #result = []\n",
    "    #for a in range(len(f1)):\n",
    "    #    result.append(pt.stem(f1[a]))\n",
    "    \n",
    "    cnt = collections.Counter()\n",
    "    for word in f1: #result\n",
    "        cnt[word] += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnt = tokenize(direc)\n",
    "#cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for a in range(len(direc)):\n",
    "    df = df+list(tokenize(direc[a])) # count document term in collecitions\n",
    "    cnt = collections.Counter()\n",
    "    for word in df:\n",
    "        cnt[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12413"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = cnt.most_common()\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_index</th>\n",
       "      <th>term</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>president</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>america</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>us</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>one</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>country</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>know</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>going</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>want</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>way</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>go</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>get</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>every</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>say</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>time</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>make</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>tell</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>right</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>new</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>need</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>would</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>united</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>many</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>years</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>said</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>much</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>like</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>states</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>great</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>12383</td>\n",
       "      <td>hellholes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12384</th>\n",
       "      <td>12384</td>\n",
       "      <td>frenchmen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>12385</td>\n",
       "      <td>berets</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>12386</td>\n",
       "      <td>chainsmoking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>12387</td>\n",
       "      <td>laureate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12388</th>\n",
       "      <td>12388</td>\n",
       "      <td>reconsiders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12389</th>\n",
       "      <td>12389</td>\n",
       "      <td>lieberman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12390</th>\n",
       "      <td>12390</td>\n",
       "      <td>scoop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12391</th>\n",
       "      <td>12391</td>\n",
       "      <td>rarer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12392</th>\n",
       "      <td>12392</td>\n",
       "      <td>ieds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12393</th>\n",
       "      <td>12393</td>\n",
       "      <td>soleimani</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12394</th>\n",
       "      <td>12394</td>\n",
       "      <td>bury</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12395</th>\n",
       "      <td>12395</td>\n",
       "      <td>caesar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12396</th>\n",
       "      <td>12396</td>\n",
       "      <td>praise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "      <td>12397</td>\n",
       "      <td>behaves</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>12398</td>\n",
       "      <td>decrees</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>12399</td>\n",
       "      <td>exempt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>12400</td>\n",
       "      <td>listens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12401</th>\n",
       "      <td>12401</td>\n",
       "      <td>“mitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12402</th>\n",
       "      <td>12402</td>\n",
       "      <td>emp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12403</th>\n",
       "      <td>12403</td>\n",
       "      <td>electromagnetic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12404</th>\n",
       "      <td>12404</td>\n",
       "      <td>pulse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>12405</td>\n",
       "      <td>electrical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12406</th>\n",
       "      <td>12406</td>\n",
       "      <td>grid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "      <td>12407</td>\n",
       "      <td>seaboard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "      <td>12408</td>\n",
       "      <td>showvote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12409</th>\n",
       "      <td>12409</td>\n",
       "      <td>“lets</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>12410</td>\n",
       "      <td>silas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>12411</td>\n",
       "      <td>naïve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>12412</td>\n",
       "      <td>cruzorg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t_index             term  df\n",
       "0           0           people  93\n",
       "1           1        president  92\n",
       "2           2          america  92\n",
       "3           3               us  91\n",
       "4           4              one  90\n",
       "5           5          country  89\n",
       "6           6             know  88\n",
       "7           7            going  88\n",
       "8           8            world  88\n",
       "9           9             want  88\n",
       "10         10              way  87\n",
       "11         11               go  87\n",
       "12         12              get  87\n",
       "13         13            every  86\n",
       "14         14              say  86\n",
       "15         15             time  86\n",
       "16         16             make  86\n",
       "17         17             tell  85\n",
       "18         18            right  85\n",
       "19         19              new  85\n",
       "20         20             need  85\n",
       "21         21            would  85\n",
       "22         22           united  84\n",
       "23         23             many  84\n",
       "24         24            years  84\n",
       "25         25             said  83\n",
       "26         26             much  83\n",
       "27         27             like  83\n",
       "28         28           states  82\n",
       "29         29            great  82\n",
       "...       ...              ...  ..\n",
       "12383   12383        hellholes   1\n",
       "12384   12384        frenchmen   1\n",
       "12385   12385           berets   1\n",
       "12386   12386     chainsmoking   1\n",
       "12387   12387         laureate   1\n",
       "12388   12388      reconsiders   1\n",
       "12389   12389        lieberman   1\n",
       "12390   12390            scoop   1\n",
       "12391   12391            rarer   1\n",
       "12392   12392             ieds   1\n",
       "12393   12393        soleimani   1\n",
       "12394   12394             bury   1\n",
       "12395   12395           caesar   1\n",
       "12396   12396           praise   1\n",
       "12397   12397          behaves   1\n",
       "12398   12398          decrees   1\n",
       "12399   12399           exempt   1\n",
       "12400   12400          listens   1\n",
       "12401   12401           “mitch   1\n",
       "12402   12402              emp   1\n",
       "12403   12403  electromagnetic   1\n",
       "12404   12404            pulse   1\n",
       "12405   12405       electrical   1\n",
       "12406   12406             grid   1\n",
       "12407   12407         seaboard   1\n",
       "12408   12408         showvote   1\n",
       "12409   12409            “lets   1\n",
       "12410   12410            silas   1\n",
       "12411   12411            naïve   1\n",
       "12412   12412          cruzorg   1\n",
       "\n",
       "[12413 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = dict()\n",
    "for a in range(len(dictionary)):\n",
    "    d1.update({a: list(dictionary[a])})\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame.from_dict(d1, orient='index')\n",
    "df = df.rename(index=str, columns={0: 'term', 1:'df'})\n",
    "#df.index = np.arange(1, len(df) + 1)\n",
    "df['t_index'] = df.index\n",
    "df = df[['t_index', 'term', 'df']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+\"\\dictionary.txt\", header=None, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_doc_to_tfidf(file_path):\n",
    "    # 把字典dictionary 讀進來，只需要1,2欄\n",
    "    dic = pd.read_csv('dictionary.txt', sep = '\\t', header = None, usecols = [1,2])\n",
    "    dic = dic.rename(index=str, columns={1: 'term', 2:'df'}) #命名\n",
    "    \n",
    "    # 用字典來比對，字典包含文件x，則取出文件x的df\n",
    "    doc_df = dic.loc[dic['term'].isin(list(tokenize(file_path)))] \n",
    "    doc_df = doc_df.reset_index()\n",
    "    doc_df = doc_df.rename(index=str, columns={'index': 't_index'}) #命名\n",
    "    \n",
    "    # 計算idf, 輸入文件總數, df\n",
    "    def idf_calculator(len_direc, doc_freq):\n",
    "        idf = math.log10(len_direc/doc_freq)\n",
    "        return idf\n",
    "    idf = []\n",
    "    for a in range(len(doc_df)):\n",
    "            idf.append(idf_calculator(len(direc), doc_df.iloc[a]['df']))\n",
    "    doc_df['idf'] = idf # 新增idf 這欄，以上面計算好的idf list 加上\n",
    "    doc_df = doc_df.sort_values(by=['term'], ascending = True) # 以字順排序\n",
    "    \n",
    "    tf = tokenize(file_path).most_common()\n",
    "    doc_tf = []\n",
    "    for a in range(len(tf)):\n",
    "        doc_tf.append(list(tf[a])) # 把tuple轉成 list\n",
    "    doc_tf = pd.DataFrame(doc_tf) # 再轉成 dataframe\n",
    "    doc_tf = doc_tf.rename(index=str, columns={0: 'term', 1:'tf'}) # 命名\n",
    "    doc_tf = doc_tf.sort_values(by=['term'], ascending = True) # 以字順排序\n",
    "    doc_df['tf'] = list(doc_tf['tf']) # 把 tf加上去 原本doc_df\n",
    "    doc_df['tf_idf'] = doc_df.idf*doc_df.tf # 新增 tf_idf欄位，兩欄相乘\n",
    "    \n",
    "    #再補一個length normalize\n",
    "    doc_df['Norm_tf_idf'] = doc_df.tf_idf/((sum(doc_df.tf_idf**2))**0.5)\n",
    "\n",
    "    doc_df = doc_df.sort_values(by=['Norm_tf_idf'], ascending = False) # 以Norm_tf_idf大小排序，大到小\n",
    "    \n",
    "    return doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_index</th>\n",
       "      <th>term</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>Norm_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>5437</td>\n",
       "      <td>fork</td>\n",
       "      <td>2</td>\n",
       "      <td>1.676694</td>\n",
       "      <td>3</td>\n",
       "      <td>5.030081</td>\n",
       "      <td>0.224601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1248</td>\n",
       "      <td>road</td>\n",
       "      <td>16</td>\n",
       "      <td>0.773604</td>\n",
       "      <td>6</td>\n",
       "      <td>4.641622</td>\n",
       "      <td>0.207255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2543</td>\n",
       "      <td>pipeline</td>\n",
       "      <td>7</td>\n",
       "      <td>1.132626</td>\n",
       "      <td>3</td>\n",
       "      <td>3.397877</td>\n",
       "      <td>0.151720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2339</td>\n",
       "      <td>experts</td>\n",
       "      <td>8</td>\n",
       "      <td>1.074634</td>\n",
       "      <td>3</td>\n",
       "      <td>3.223901</td>\n",
       "      <td>0.143952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>519</td>\n",
       "      <td>climate</td>\n",
       "      <td>35</td>\n",
       "      <td>0.433656</td>\n",
       "      <td>7</td>\n",
       "      <td>3.035589</td>\n",
       "      <td>0.135544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1536</td>\n",
       "      <td>turnout</td>\n",
       "      <td>13</td>\n",
       "      <td>0.863780</td>\n",
       "      <td>3</td>\n",
       "      <td>2.591341</td>\n",
       "      <td>0.115707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>678</td>\n",
       "      <td>black</td>\n",
       "      <td>29</td>\n",
       "      <td>0.515326</td>\n",
       "      <td>5</td>\n",
       "      <td>2.576628</td>\n",
       "      <td>0.115050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>3243</td>\n",
       "      <td>imperative</td>\n",
       "      <td>5</td>\n",
       "      <td>1.278754</td>\n",
       "      <td>2</td>\n",
       "      <td>2.557507</td>\n",
       "      <td>0.114196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3247</td>\n",
       "      <td>lesson</td>\n",
       "      <td>5</td>\n",
       "      <td>1.278754</td>\n",
       "      <td>2</td>\n",
       "      <td>2.557507</td>\n",
       "      <td>0.114196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1333</td>\n",
       "      <td>fossil</td>\n",
       "      <td>15</td>\n",
       "      <td>0.801632</td>\n",
       "      <td>3</td>\n",
       "      <td>2.404897</td>\n",
       "      <td>0.107382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2857</td>\n",
       "      <td>prove</td>\n",
       "      <td>6</td>\n",
       "      <td>1.199572</td>\n",
       "      <td>2</td>\n",
       "      <td>2.399145</td>\n",
       "      <td>0.107125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2861</td>\n",
       "      <td>popular</td>\n",
       "      <td>6</td>\n",
       "      <td>1.199572</td>\n",
       "      <td>2</td>\n",
       "      <td>2.399145</td>\n",
       "      <td>0.107125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>800</td>\n",
       "      <td>establishment</td>\n",
       "      <td>25</td>\n",
       "      <td>0.579784</td>\n",
       "      <td>4</td>\n",
       "      <td>2.319134</td>\n",
       "      <td>0.103553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1192</td>\n",
       "      <td>voter</td>\n",
       "      <td>17</td>\n",
       "      <td>0.747275</td>\n",
       "      <td>3</td>\n",
       "      <td>2.241824</td>\n",
       "      <td>0.100101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>138</td>\n",
       "      <td>political</td>\n",
       "      <td>62</td>\n",
       "      <td>0.185332</td>\n",
       "      <td>12</td>\n",
       "      <td>2.223983</td>\n",
       "      <td>0.099304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1117</td>\n",
       "      <td>fuel</td>\n",
       "      <td>18</td>\n",
       "      <td>0.722451</td>\n",
       "      <td>3</td>\n",
       "      <td>2.167353</td>\n",
       "      <td>0.096776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2340</td>\n",
       "      <td>nafta</td>\n",
       "      <td>8</td>\n",
       "      <td>1.074634</td>\n",
       "      <td>2</td>\n",
       "      <td>2.149267</td>\n",
       "      <td>0.095968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>997</td>\n",
       "      <td>difficult</td>\n",
       "      <td>20</td>\n",
       "      <td>0.676694</td>\n",
       "      <td>3</td>\n",
       "      <td>2.030081</td>\n",
       "      <td>0.090646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7291</td>\n",
       "      <td>ex</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>7292</td>\n",
       "      <td>withdrawing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>7302</td>\n",
       "      <td>eventful</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>7288</td>\n",
       "      <td>precedent</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>7301</td>\n",
       "      <td>dirtiest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>7296</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>7304</td>\n",
       "      <td>expedient</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>7289</td>\n",
       "      <td>knox</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>7295</td>\n",
       "      <td>lick</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>7297</td>\n",
       "      <td>lesbians</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>7294</td>\n",
       "      <td>commodity</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>7298</td>\n",
       "      <td>lesbian</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29</td>\n",
       "      <td>great</td>\n",
       "      <td>82</td>\n",
       "      <td>0.063910</td>\n",
       "      <td>2</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.005707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31</td>\n",
       "      <td>let</td>\n",
       "      <td>82</td>\n",
       "      <td>0.063910</td>\n",
       "      <td>2</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.005707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>81</td>\n",
       "      <td>weve</td>\n",
       "      <td>71</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>0.005647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>80</td>\n",
       "      <td>ago</td>\n",
       "      <td>71</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>0.005647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>82</td>\n",
       "      <td>young</td>\n",
       "      <td>71</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>0.005647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>76</td>\n",
       "      <td>understand</td>\n",
       "      <td>72</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>77</td>\n",
       "      <td>stop</td>\n",
       "      <td>72</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>one</td>\n",
       "      <td>90</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>5</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>said</td>\n",
       "      <td>83</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>73</td>\n",
       "      <td>could</td>\n",
       "      <td>73</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>71</td>\n",
       "      <td>dollars</td>\n",
       "      <td>73</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>70</td>\n",
       "      <td>together</td>\n",
       "      <td>73</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>president</td>\n",
       "      <td>92</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.004978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>93</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>12</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>0.004951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>61</td>\n",
       "      <td>care</td>\n",
       "      <td>74</td>\n",
       "      <td>0.108492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108492</td>\n",
       "      <td>0.004844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>65</td>\n",
       "      <td>talk</td>\n",
       "      <td>74</td>\n",
       "      <td>0.108492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108492</td>\n",
       "      <td>0.004844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>57</td>\n",
       "      <td>even</td>\n",
       "      <td>75</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>0.004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>53</td>\n",
       "      <td>look</td>\n",
       "      <td>76</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50</td>\n",
       "      <td>life</td>\n",
       "      <td>77</td>\n",
       "      <td>0.091233</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091233</td>\n",
       "      <td>0.004074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>say</td>\n",
       "      <td>86</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086450</td>\n",
       "      <td>0.003860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>make</td>\n",
       "      <td>86</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086450</td>\n",
       "      <td>0.003860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>america</td>\n",
       "      <td>92</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>5</td>\n",
       "      <td>0.069679</td>\n",
       "      <td>0.003111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>37</td>\n",
       "      <td>come</td>\n",
       "      <td>81</td>\n",
       "      <td>0.069239</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069239</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "      <td>88</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>much</td>\n",
       "      <td>83</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>many</td>\n",
       "      <td>84</td>\n",
       "      <td>0.053444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053444</td>\n",
       "      <td>0.002386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>new</td>\n",
       "      <td>85</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>get</td>\n",
       "      <td>87</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>go</td>\n",
       "      <td>87</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>us</td>\n",
       "      <td>91</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037364</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    t_index           term  df       idf  tf    tf_idf  Norm_tf_idf\n",
       "452    5437           fork   2  1.676694   3  5.030081     0.224601\n",
       "335    1248           road  16  0.773604   6  4.641622     0.207255\n",
       "407    2543       pipeline   7  1.132626   3  3.397877     0.151720\n",
       "400    2339        experts   8  1.074634   3  3.223901     0.143952\n",
       "234     519        climate  35  0.433656   7  3.035589     0.135544\n",
       "360    1536        turnout  13  0.863780   3  2.591341     0.115707\n",
       "267     678          black  29  0.515326   5  2.576628     0.115050\n",
       "426    3243     imperative   5  1.278754   2  2.557507     0.114196\n",
       "430    3247         lesson   5  1.278754   2  2.557507     0.114196\n",
       "345    1333         fossil  15  0.801632   3  2.404897     0.107382\n",
       "411    2857          prove   6  1.199572   2  2.399145     0.107125\n",
       "415    2861        popular   6  1.199572   2  2.399145     0.107125\n",
       "290     800  establishment  25  0.579784   4  2.319134     0.103553\n",
       "331    1192          voter  17  0.747275   3  2.241824     0.100101\n",
       "98      138      political  62  0.185332  12  2.223983     0.099304\n",
       "324    1117           fuel  18  0.722451   3  2.167353     0.096776\n",
       "401    2340          nafta   8  1.074634   2  2.149267     0.095968\n",
       "306     997      difficult  20  0.676694   3  2.030081     0.090646\n",
       "466    7291             ex   1  1.977724   1  1.977724     0.088308\n",
       "467    7292    withdrawing   1  1.977724   1  1.977724     0.088308\n",
       "477    7302       eventful   1  1.977724   1  1.977724     0.088308\n",
       "463    7288      precedent   1  1.977724   1  1.977724     0.088308\n",
       "476    7301       dirtiest   1  1.977724   1  1.977724     0.088308\n",
       "471    7296            wet   1  1.977724   1  1.977724     0.088308\n",
       "479    7304      expedient   1  1.977724   1  1.977724     0.088308\n",
       "464    7289           knox   1  1.977724   1  1.977724     0.088308\n",
       "470    7295           lick   1  1.977724   1  1.977724     0.088308\n",
       "472    7297       lesbians   1  1.977724   1  1.977724     0.088308\n",
       "469    7294      commodity   1  1.977724   1  1.977724     0.088308\n",
       "473    7298        lesbian   1  1.977724   1  1.977724     0.088308\n",
       "..      ...            ...  ..       ...  ..       ...          ...\n",
       "26       29          great  82  0.063910   2  0.127820     0.005707\n",
       "28       31            let  82  0.063910   2  0.127820     0.005707\n",
       "67       81           weve  71  0.126465   1  0.126465     0.005647\n",
       "66       80            ago  71  0.126465   1  0.126465     0.005647\n",
       "68       82          young  71  0.126465   1  0.126465     0.005647\n",
       "63       76     understand  72  0.120391   1  0.120391     0.005376\n",
       "64       77           stop  72  0.120391   1  0.120391     0.005376\n",
       "4         4            one  90  0.023481   5  0.117405     0.005242\n",
       "23       25           said  83  0.058646   2  0.117291     0.005237\n",
       "61       73          could  73  0.114401   1  0.114401     0.005108\n",
       "59       71        dollars  73  0.114401   1  0.114401     0.005108\n",
       "58       70       together  73  0.114401   1  0.114401     0.005108\n",
       "1         1      president  92  0.013936   8  0.111486     0.004978\n",
       "0         0         people  93  0.009241  12  0.110888     0.004951\n",
       "50       61           care  74  0.108492   1  0.108492     0.004844\n",
       "54       65           talk  74  0.108492   1  0.108492     0.004844\n",
       "48       57           even  75  0.102662   1  0.102662     0.004584\n",
       "44       53           look  76  0.096910   1  0.096910     0.004327\n",
       "43       50           life  77  0.091233   1  0.091233     0.004074\n",
       "13       14            say  86  0.043225   2  0.086450     0.003860\n",
       "15       16           make  86  0.043225   2  0.086450     0.003860\n",
       "2         2        america  92  0.013936   5  0.069679     0.003111\n",
       "34       37           come  81  0.069239   1  0.069239     0.003092\n",
       "8         8          world  88  0.033241   2  0.066482     0.002969\n",
       "24       26           much  83  0.058646   1  0.058646     0.002619\n",
       "21       23           many  84  0.053444   1  0.053444     0.002386\n",
       "18       19            new  85  0.048305   1  0.048305     0.002157\n",
       "11       12            get  87  0.038204   1  0.038204     0.001706\n",
       "10       11             go  87  0.038204   1  0.038204     0.001706\n",
       "3         3             us  91  0.018682   2  0.037364     0.001668\n",
       "\n",
       "[481 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_doc_to_tfidf(direc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(direc)):\n",
    "    #補一個 文件 term 總數在開頭\n",
    "    term_num = len(tokenize(direc[a]).most_common()) #This document has \"term_num\" terms.\n",
    "    f = open(path+\"\\Doc\"+str(a+1)+\".txt\", 'w')\n",
    "    f.write('This document has ' + str(term_num) + ' terms. ' + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\qqoao\\\\Desktop\\\\Github\\\\107-2 Language, Cognition, Computation\\\\data\\\\Ted Cruz\\\\rawdata\\\\19. Ted Cruz’s speech at Liberty University.txt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "for a in range(len(direc)):\n",
    "    print(a)\n",
    "    transfer_doc_to_tfidf(direc[a]).to_csv(path+\"\\Doc\"+str(a+1)+\".txt\", header=True, index=None, sep='\\t', mode='a', columns=['t_index','term', 'Norm_tf_idf'])\n",
    "    #mode = 'a' 往文件後面加上; sep = '\\t' 以tab分隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_sim(docx,docy): #輸入兩file_path\n",
    "    # 首先把兩個檔讀進來 fx跟fy\n",
    "    fa = pd.read_csv(docx, sep = '\\t', header = 'infer', skiprows=1, usecols=[0,1,2])\n",
    "    fb = pd.read_csv(docy, sep = '\\t', header = 'infer', skiprows=1, usecols=[0,1,2])\n",
    "    # 找到兩個都存在的term，另存成fm, fn\n",
    "    fm = fb[fb['t_index'].isin(fa['t_index'])]\n",
    "    fn = fa[fa['t_index'].isin(fb['t_index'])]\n",
    "    # 依照t_index排序\n",
    "    fm = fm.sort_values(by=['t_index'], ascending = True)\n",
    "    fn = fn.sort_values(by=['t_index'], ascending = True)\n",
    "    # 把t_index設成index, 如此才不會無法兩相對應\n",
    "    fm = fm.set_index(['t_index'])\n",
    "    fn = fn.set_index(['t_index'])\n",
    "    # 新增一欄x, 把fm, fn兩個tf_idf相乘\n",
    "    fm['x'] = fm.Norm_tf_idf*fn.Norm_tf_idf\n",
    "    # 把上述欄相加，就是內積的結果\n",
    "    cosin = sum(fm.x) \n",
    "    return cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06198216629936714"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_sim('Doc1.txt', 'Doc28.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
