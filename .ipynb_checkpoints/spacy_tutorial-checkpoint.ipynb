{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy \n",
    "1. [Linguistic Feature](https://spacy.io/usage/linguistic-features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "Building wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py): started\n",
      "  Building wheel for en-core-web-lg (setup.py): still running...\n",
      "  Building wheel for en-core-web-lg (setup.py): still running...\n",
      "  Building wheel for en-core-web-lg (setup.py): still running...\n",
      "  Building wheel for en-core-web-lg (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\qqoao\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-01aqp9j7\\wheels\\b4\\d7\\70\\426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm --user\n",
    "#!python -m spacy download en_core_web_md --user\n",
    "#!python -m spacy download en_core_web_lg --user\n",
    "#!python -m spacy download en --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously. “I can tell you very senior CEOs of major American car companies would shake my hand and turn away because I wasn’t worth talking to,” said Thrun, in an interview with Recode earlier this week."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'be', 'talk', 'say']\n"
     ]
    }
   ],
   "source": [
    "print([token.lemma_ for token in doc if token.pos_=='VERB']) #VERB, NOUN, ADJ, ADV, ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'be', 'talk', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode ORG\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous amod cars NOUN []\n",
      "cars nsubj shift VERB [Autonomous]\n",
      "shift ROOT shift VERB [cars, liability]\n",
      "insurance compound liability NOUN []\n",
      "liability dobj shift VERB [insurance, toward]\n",
      "toward prep liability NOUN [manufacturers]\n",
      "manufacturers pobj toward ADP []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for token in doc:\n",
    "    d = {'4_CHILDREN' : [child for child in token.children], \n",
    "         '3_HEAD POS' : token.head.pos_,\n",
    "         '2_DEP' : token.dep_,\n",
    "         '1_HEAD TEXT' : token.head.text, \n",
    "         '0_TEXT' : token.text}\n",
    "    df = df.append(d, ignore_index=True)\n",
    "    #print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "    #        [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_TEXT</th>\n",
       "      <th>1_HEAD TEXT</th>\n",
       "      <th>2_DEP</th>\n",
       "      <th>3_HEAD POS</th>\n",
       "      <th>4_CHILDREN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous</td>\n",
       "      <td>cars</td>\n",
       "      <td>amod</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>shift</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[Autonomous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shift</td>\n",
       "      <td>shift</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[cars, liability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insurance</td>\n",
       "      <td>liability</td>\n",
       "      <td>compound</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>shift</td>\n",
       "      <td>dobj</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[insurance, toward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toward</td>\n",
       "      <td>liability</td>\n",
       "      <td>prep</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[manufacturers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>toward</td>\n",
       "      <td>pobj</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_TEXT 1_HEAD TEXT     2_DEP 3_HEAD POS           4_CHILDREN\n",
       "0     Autonomous        cars      amod       NOUN                   []\n",
       "1           cars       shift     nsubj       VERB         [Autonomous]\n",
       "2          shift       shift      ROOT       VERB    [cars, liability]\n",
       "3      insurance   liability  compound       NOUN                   []\n",
       "4      liability       shift      dobj       VERB  [insurance, toward]\n",
       "5         toward   liability      prep       NOUN      [manufacturers]\n",
       "6  manufacturers      toward      pobj        ADP                   []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{shift}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "\n",
    "# Finding a verb with a subject from below — good\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        verbs.add(possible_subject.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IOB Scheme  \n",
    "    I – Token is inside an entity.  \n",
    "    O – Token is outside an entity.  \n",
    "    B – Token is the beginning of an entity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_TEXT</th>\n",
       "      <th>1_start</th>\n",
       "      <th>2_end</th>\n",
       "      <th>3_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_TEXT  1_start  2_end 3_Label\n",
       "0  San Francisco        0     13     GPE"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"San Francisco considers banning sidewalk delivery robots\")\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "d = ents\n",
    "df = df.append(d, ignore_index=True)\n",
    "df.columns = ['0_TEXT', '1_start', '2_end', '3_Label']\n",
    "# token level\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_TEXT</th>\n",
       "      <th>1_IOB</th>\n",
       "      <th>2_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San</td>\n",
       "      <td>B</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Francisco</td>\n",
       "      <td>I</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>considers</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0_TEXT 1_IOB 2_Type\n",
       "0        San     B    GPE\n",
       "1  Francisco     I    GPE\n",
       "2  considers     O       "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "ent_san = {'0_TEXT':doc[0].text, '1_IOB':doc[0].ent_iob_, '2_Type':doc[0].ent_type_}\n",
    "ent_francisco = {'0_TEXT':doc[1].text, '1_IOB':doc[1].ent_iob_, '2_Type':doc[1].ent_type_}\n",
    "ent_considers = {'0_TEXT':doc[2].text, '1_IOB':doc[2].ent_iob_, '2_Type':doc[2].ent_type_}\n",
    "\n",
    "df = df.append(ent_san, ignore_index=True)\n",
    "df = df.append(ent_francisco, ignore_index=True)\n",
    "df = df.append(ent_considers, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
